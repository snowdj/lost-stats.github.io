
<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">
    <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script>
  <script type="text/javascript" src="/assets/js/just-the-docs.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Penalized Regression | LOST</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Penalized Regression" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="LOST" />
<script type="application/ld+json">
{"@type":"WebPage","url":"/Machine_Learning/penalized_regression.html","headline":"Penalized Regression","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML">
  </script>
</head>
<body>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
      <title>Link</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
        <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
      </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
      <title>Search</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
        <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
      </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
      <title>Menu</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
        <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
      </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
      <title>Expand</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
        <polyline points="9 18 15 12 9 6"></polyline>
      </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
      <title>Document</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
        <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
      </svg>
    </symbol>
  </svg>
  <div class="side-bar">
    <div class="site-header">
      <a href="/" class="site-title lh-tight">
  LOST
</a>
      <a href="#" id="menu-button" class="site-button">
        <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
      </a>
    </div>
    <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
      <ul class="nav-list"><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/data_manipulation.html" class="nav-list-link">Data Manipulation</a><ul class="nav-list "><li class="nav-list-item "><a href="/Data_Manipulation/collapse_a_data_set.html" class="nav-list-link">Collapse a Data Set</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/Combining_Datasets/combining_datasets_overview.html" class="nav-list-link">Combining Datasets</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Combining_Datasets/combining_datasets_vertical_combination.html" class="nav-list-link">Vertical Combination</a>
                      </li><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Combining_Datasets/combining_datasets_horizontal_merge_deterministic.html" class="nav-list-link">Horizontal Combination (Deterministic)</a>
                      </li></ul></li><li class="nav-list-item "><a href="/Data_Manipulation/Creating_Dummy_Variables/creating_dummy_variables.html" class="nav-list-link">Creating Dummy Variables</a></li><li class="nav-list-item "><a href="/Data_Manipulation/determine_the_observation_level_of_a_data_set.html" class="nav-list-link">Determine the Observation Level of a Data Set</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Data_Manipulation/Reshaping/reshape.html" class="nav-list-link">Reshaping Data</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_wide_to_long.html" class="nav-list-link">Reshape Panel Data from Wide to Long</a>
                      </li><li class="nav-list-item ">
                        <a href="/Data_Manipulation/Reshaping/reshape_panel_data_from_long_to_wide.html" class="nav-list-link">Reshape Panel Data from Long to Wide</a>
                      </li></ul></li><li class="nav-list-item "><a href="/Data_Manipulation/rowwise_calculations.html" class="nav-list-link">Rowwise Calculations</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Geo-Spatial/Geo-spatial.html" class="nav-list-link">Geo-Spatial</a><ul class="nav-list "><li class="nav-list-item "><a href="/Geo-Spatial/choropleths.html" class="nav-list-link">Choropleths</a></li><li class="nav-list-item "><a href="/Geo-Spatial/geocoding.html" class="nav-list-link">Geocoding</a></li><li class="nav-list-item "><a href="/Geo-Spatial/merging_shape_files.html" class="nav-list-link">Merging Shape Files</a></li><li class="nav-list-item "><a href="/Geo-Spatial/spatial_joins.html" class="nav-list-link">Spatial Joins</a></li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Machine_Learning/Machine_Learning.html" class="nav-list-link">Machine Learning</a><ul class="nav-list "><li class="nav-list-item "><a href="/Machine_Learning/artificial_neural_network.html" class="nav-list-link">Artificial Neural Network</a></li><li class="nav-list-item "><a href="/Machine_Learning/boosted_regression_trees.html" class="nav-list-link">Boosted Regression Trees</a></li><li class="nav-list-item "><a href="/Machine_Learning/causal_forest.html" class="nav-list-link">Causal Forest</a></li><li class="nav-list-item "><a href="/Machine_Learning/decision_trees.html" class="nav-list-link">Decision Trees</a></li><li class="nav-list-item  active"><a href="/Machine_Learning/penalized_regression.html" class="nav-list-link active">Penalized Regression</a></li><li class="nav-list-item "><a href="/Machine_Learning/random_forest.html" class="nav-list-link">Random Forest</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Model_Estimation.html" class="nav-list-link">Model Estimation</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/OLS/OLS.html" class="nav-list-link">Ordinary Least Squares</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/simple_linear_regression.html" class="nav-list-link">Simple Linear Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/interaction_terms_and_polynomials.html" class="nav-list-link">Interaction Terms and Polynomials</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/OLS/fixed_effects_in_linear_regression.html" class="nav-list-link">Fixed Effects in Linear Regression</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/GLS/GLS.html" class="nav-list-link">Generalised Least Squares</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/heckman_correction_model.html" class="nav-list-link">Heckman Correction Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/logit_model.html" class="nav-list-link">Logit Model</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/mcfaddens_choice_model.html" class="nav-list-link">McFadden's Choice Model (Alternative-Specific Conditional Logit)</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/GLS/probit_model.html" class="nav-list-link">Probit Model</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Multilevel_Models/Multilevel_Models.html" class="nav-list-link">Multilevel Models</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Multilevel_Models/linear_mixed_effects_regression.html" class="nav-list-link">Linear Mixed-Effects Regression</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Multilevel_Models/random_mixed_effects_estimation.html" class="nav-list-link">Random/Mixed Effects in Linear Regression</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Research_Design/Research_Design.html" class="nav-list-link">Research Design</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/instrumental_variables.html" class="nav-list-link">Instrumental Variables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/regression_discontinuity_design.html" class="nav-list-link">Regression Discontinuity Design</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Research_Design/two_by_two_difference_in_difference.html" class="nav-list-link">2x2 Difference in Difference</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Model_Estimation/Statistical_Inference/Statistical_Inference.html" class="nav-list-link">Statistical Inference</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/linear_hypothesis_tests.html" class="nav-list-link">Linear Hypothesis Tests</a>
                      </li><li class="nav-list-item ">
                        <a href="/Model_Estimation/Statistical_Inference/Nonstandard_Errors/nonstandard_errors.html" class="nav-list-link">Nonstandard Errors</a>
                      </li></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Presentation.html" class="nav-list-link">Presentation</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Figures/Figures.html" class="nav-list-link">Figures</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Scatterplots.html" class="nav-list-link">Scatterplots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/Styling_Scatterplots.html" class="nav-list-link">Styling Scatterplots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/bar_graphs.html" class="nav-list-link">Bar Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/density_plots.html" class="nav-list-link">Density Plots</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/faceted_graphs.html" class="nav-list-link">Faceted Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/heatmap_colored_correlation_matrix.html" class="nav-list-link">Heatmap Colored Correlation Matrix</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/histograms.html" class="nav-list-link">Histograms</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/line_graph_with_labels_at_the_beginning_or_end.html" class="nav-list-link">Line Graph with Labels at the Beginning or End of Lines</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/line_graphs.html" class="nav-list-link">Line Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/marginal_effects_plots_for_interactions_with_continuous_variables.html" class="nav-list-link">Marginal Effects Plots for Interactions with Continuous Variables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/scatterplot_by_group_on_shared_axes.html" class="nav-list-link">Scatterplot by Group on Shared Axes</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/styling_line_graphs.html" class="nav-list-link">Styling Line Graphs</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Figures/formatting_graph_legends.html" class="nav-list-link">Formatting Graph Legends</a>
                      </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Presentation/Tables/Tables.html" class="nav-list-link">Tables</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Balance_Tables.html" class="nav-list-link">Balance Tables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Regression_Tables.html" class="nav-list-link">Regression Tables</a>
                      </li><li class="nav-list-item ">
                        <a href="/Presentation/Tables/Summary_Statistics_Tables.html" class="nav-list-link">Summary Statistics Tables</a>
                      </li></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Time_Series/Time_Series.html" class="nav-list-link">Time Series</a><ul class="nav-list "><li class="nav-list-item "><a href="/Time_Series/AR-models.html" class="nav-list-link">AR Models</a></li><li class="nav-list-item "><a href="/Time_Series/ARCH_Model.html" class="nav-list-link">ARCH Model</a></li><li class="nav-list-item "><a href="/Time_Series/ARMA-models.html" class="nav-list-link">ARMA Models</a></li><li class="nav-list-item "><a href="/Time_Series/GARCH_Model.html" class="nav-list-link">GARCH Model</a></li><li class="nav-list-item "><a href="/Time_Series/Granger_Causality.html" class="nav-list-link">Granger Causality</a></li><li class="nav-list-item "><a href="/Time_Series/creating_time_series_dataset.html" class="nav-list-link">Creating Time Series Dataset</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/Other/Other.html" class="nav-list-link">Other</a><ul class="nav-list "><li class="nav-list-item "><a href="/Other/create_a_conda_package.html" class="nav-list-link">Create a Conda Package (Python)</a></li><li class="nav-list-item "><a href="/Other/get_a_list_of_files.html" class="nav-list-link">Get a List of Files</a></li><li class="nav-list-item "><a href="/Other/import_a_foreign_data_file.html" class="nav-list-link">Import a Foreign Data File</a></li></ul></li><li class="nav-list-item"><a href="/Desired_Nonexistent_Pages/desired_nonexistent_pages.html" class="nav-list-link">Desired Nonexistent Pages</a></li><li class="nav-list-item"><a href="/Contributing/Contributing.html" class="nav-list-link">Contributing</a></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li></ul>
    </nav>
    <footer class="site-footer">
      This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  </div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
        <div class="search">
          <div class="search-input-wrap">
            <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search LOST" aria-label="Search LOST" autocomplete="off">
            <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
          </div>
          <div id="search-results" class="search-results"></div>
        </div>
    </div>
    <div id="main-content-wrap" class="main-content-wrap">
          <nav aria-label="Breadcrumb" class="breadcrumb-nav">
            <ol class="breadcrumb-nav-list">
                <li class="breadcrumb-nav-list-item"><a href="/Machine_Learning/Machine_Learning.html">Machine Learning</a></li>
              <li class="breadcrumb-nav-list-item"><span>Penalized Regression</span></li>
            </ol>
          </nav>
      <div id="main-content" class="main-content" role="main">
          <h1 id="penalized-regression">
          <a href="#penalized-regression" aria-labelledby="penalized-regression" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Penalized Regression
      </h1>
<p>When running a regression, especially one with many predictors, the results have a tendency to overfit the data, reducing out-of-sample predictive properties.</p>
<p>Penalized regression eases this problem by forcing the regression estimator to shrink its coefficients towards 0 in order to avoid the “penalty” term imposed on the coefficients. This process is closely related to the idea of Bayesian shrinkage, and indeed standard penalized regression results are equivalent to regression performed using <a href="https://amstat.tandfonline.com/doi/abs/10.1198/016214508000000337?casa_token=DE6O93Bz7uUAAAAA:Ff_MiPXvPH32NA2hnGtZtqb8grXEiEqF0fdO3B0p_a6wOaqRciCZ4ASwxn69gdOb93Lbt-HSyK1o4As">certain Bayesian priors</a>.</p>
<p>Regular OLS selects coefficients \(\hat{\beta}\) to minimize the sum of squared errors:</p>
\[\min\sum_i(y_i - X_i\hat{\beta})^2\]
<p>Non-OLS regressions similarly select coefficients to minimize a similar objective function. Penalized regression adds a penalty term \(\lambda\lVert\beta\rVert_p\) to that objective function, where \(\lambda\) is a tuning parameter that determines how harshly to penalize coefficients, and \(\lVert\beta\rVert_p\) is the \(p\)-norm of the coefficients, or \(\sum_j\lvert\beta\rvert^p\).</p>
\[\min\left(\sum_i(y_i - X_i\hat{\beta})^2 + \lambda\left\lVert\beta\right\rVert_p \right)\]
<p>Typically \(p\) is set to 1 for LASSO regression (least absolute shrinkage and selection operator), which has the effect of tending to set coefficients to 0, i.e. model selection, or to 2 for Ridge Regression. Elastic net regression provides a weighted mix of LASSO and Ridge penalties, commonly referring to the weight as \(\alpha\).</p>
      <h2 id="keep-in-mind">
          <a href="#keep-in-mind" aria-labelledby="keep-in-mind" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Keep in Mind
      </h2>
<ul>
  <li>To avoid being penalized for a constant term, or by differences in scale between variables, it is a very good idea to standardize each variable (subtract the mean and divide by the standard deviation) before running a penalized regression.</li>
  <li>Penalized regression can be run for logit and other kinds of regression, not just linear regression. Using penalties with general linear models like logit is common.</li>
  <li>Penalized regression coefficients are designed to improve out-of-sample prediction, but they are biased. If the goal is estimation of a parameter, rather than prediction, this should be kept in mind. A common procedure is to use LASSO to select variables, and then run regular regression models with the variables that LASSO has selected.</li>
  <li>The \(\lambda\) parameter is often chosen using cross-validation. Many penalized regression commands include an option to select \(\lambda\) by cross-validation automatically.</li>
  <li>LASSO models commonly include variables along with polynomial transformation of those variables and interactions, allowing LASSO to determine which transformations are worth keeping.</li>
</ul>
      <h2 id="also-consider">
          <a href="#also-consider" aria-labelledby="also-consider" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Also Consider
      </h2>
<ul>
  <li>If it is not important to estimate coefficients but the goal is simply to predict an outcome, then there are many other <a href="/Machine_Learning/Machine_Learning.html">machine learning</a> methods that do so, and in some cases can handle higher dimensionality or work with smaller samples.</li>
</ul>
      <h1 id="implementations">
          <a href="#implementations" aria-labelledby="implementations" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementations
      </h1>
      <h2 id="r">
          <a href="#r" aria-labelledby="r" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> R
      </h2>
<p>We will use the <strong>glmnet</strong> package.</p>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Install glmnet and tidyverse if necessary</span><span class="w">
</span><span class="c1"># install.packages('glmnet', 'tidyverse')</span><span class="w">

</span><span class="c1"># Load glmnet</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span><span class="w">

</span><span class="c1"># Load iris data</span><span class="w">
</span><span class="n">data</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create a matrix with all variables other than our dependent vairable, Sepal.Length</span><span class="w">
</span><span class="c1"># and interactions. </span><span class="w">
</span><span class="c1"># -1 to omit the intercept</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">model.matrix</span><span class="p">(</span><span class="n">lm</span><span class="p">(</span><span class="n">Sepal.Length</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="p">(</span><span class="n">.</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iris</span><span class="p">))</span><span class="w">
</span><span class="c1"># Add squared terms of numeric variables</span><span class="w">
</span><span class="n">numeric.var.names</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">iris</span><span class="p">)[</span><span class="m">2</span><span class="o">:</span><span class="m">4</span><span class="p">]</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">iris</span><span class="p">[,</span><span class="n">numeric.var.names</span><span class="p">]</span><span class="o">^</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">colnames</span><span class="p">(</span><span class="n">M</span><span class="p">)[</span><span class="m">16</span><span class="o">:</span><span class="m">18</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="n">numeric.var.names</span><span class="p">,</span><span class="s1">'squared'</span><span class="p">)</span><span class="w">

</span><span class="c1"># Create a matrix for our dependent variable too</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.matrix</span><span class="p">(</span><span class="n">iris</span><span class="o">$</span><span class="n">Sepal.Length</span><span class="p">)</span><span class="w">

</span><span class="c1"># Standardize all variables</span><span class="w">
</span><span class="n">M</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scale</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">scale</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="w">


</span><span class="c1"># Use glmnet to estimate penalized regression</span><span class="w">
</span><span class="c1"># We pick family = "gaussian" for linear regression;</span><span class="w">
</span><span class="c1"># other families work for other kinds of data, like binomial for binary data</span><span class="w">
</span><span class="c1"># In each case, we use cv.glmnet to pick our lambda value using cross-validation</span><span class="w">
</span><span class="c1"># using nfolds folds for cross-validation</span><span class="w">
</span><span class="c1"># Note that alpha = 1 picks LASSO</span><span class="w">
</span><span class="n">cv.lasso</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="c1"># We might want to see how the choice of lambda relates to out-of-sample error with a plot</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">cv.lasso</span><span class="p">)</span><span class="w">
</span><span class="c1"># After doing CV, we commonly pick the lambda.min for lambda, </span><span class="w">
</span><span class="c1"># which is the lambda that minimizes out-of-sample error</span><span class="w">
</span><span class="c1"># or lambda.1se, which is one standard error above lambda.min,</span><span class="w">
</span><span class="c1"># which penalizes more harshly. The choice depends on context.</span><span class="w">
</span><span class="n">lasso.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.lasso</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">
</span><span class="c1"># coefficients are shown in the beta element. . means LASSO dropped it</span><span class="w">
</span><span class="n">lasso.model</span><span class="o">$</span><span class="n">beta</span><span class="w">

</span><span class="c1"># Running Ridge, or mixing the two with elastic net, simply means picking</span><span class="w">
</span><span class="c1"># alpha = 0 (Ridge), or 0 &lt; alpha &lt; 1 (Elastic Net)</span><span class="w">
</span><span class="n">cv.ridge</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">
</span><span class="n">ridge.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.ridge</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">

</span><span class="n">cv.elasticnet</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cv.glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">nfolds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.5</span><span class="p">)</span><span class="w">
</span><span class="n">elasticnet.model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glmnet</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gaussian"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.5</span><span class="p">,</span><span class="w"> </span><span class="n">lambda</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cv.elasticnet</span><span class="o">$</span><span class="n">lambda.min</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
      <h2 id="stata">
          <a href="#stata" aria-labelledby="stata" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Stata
      </h2>
<p>Penalized regression is one of the few machine learning algorithms that Stata does natively. This requires Stata 16. If you do not have Stata 16, you can alternately perform some forms of penalized regression by installing the <strong>lars</strong> package using <strong>ssc install lars</strong>.</p>
<div class="language-stata highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">* Use NLSY-W data
</span><span class="err">sysuse</span> <span class="err">nlsw88.dta,</span> <span class="err">clear
</span><span class="c1">
* Construct all squared and interaction terms by loop so we don't have to specify them all
* by hand in the regression function
</span><span class="err">local</span> <span class="err">numeric_vars</span> <span class="o">=</span> <span class="s2">"age grade hours ttl_exp tenure"</span><span class="err">
local</span> <span class="err">factor_vars</span> <span class="o">=</span> <span class="s2">"race married never_married collgrad south smsa c_city industry occupation union"</span><span class="err">
</span><span class="c1">
* Add all squares
</span><span class="err">foreach</span> <span class="err">x</span> <span class="err">in</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">{
</span>	<span class="err">g</span> <span class="err">sq_</span><span class="p">`</span><span class="si">x' = `x</span><span class="p">'</span><span class="o">^</span><span class="err">2
}
</span><span class="c1">
* Turn all factors into dummies so we can standardize them
</span><span class="err">local</span> <span class="err">faccount</span> <span class="o">=</span> <span class="err">1
local</span> <span class="err">dummy_vars</span> <span class="o">=</span> <span class="s2">""</span><span class="err">
foreach</span> <span class="err">x</span> <span class="err">in</span> <span class="p">`</span><span class="si">factor_vars</span><span class="p">'</span> <span class="err">{
</span>	<span class="err">xi</span> <span class="err">i.</span><span class="p">`</span><span class="si">x', pre(f`count</span><span class="p">'</span><span class="err">_)
</span>	<span class="err">local</span> <span class="err">count</span> <span class="o">=</span> <span class="p">`</span><span class="si">count</span><span class="p">'</span> <span class="o">+</span> <span class="err">1
}
</span><span class="c1">
* Add all numeric-numeric interactions; these are easy
* factor interactions would need a more thorough loop
</span><span class="err">forvalues</span> <span class="err">i</span> <span class="o">=</span> <span class="err">1(1)5</span> <span class="err">{
</span>	<span class="err">local</span> <span class="err">next_i</span> <span class="o">=</span> <span class="p">`</span><span class="si">i</span><span class="p">'</span><span class="o">+</span><span class="err">1
</span>	<span class="err">forvalues</span> <span class="err">j</span> <span class="o">=</span> <span class="p">`</span><span class="si">next_i</span><span class="p">'</span><span class="err">(1)5</span> <span class="err">{
</span>		<span class="err">local</span> <span class="err">namei</span> <span class="o">=</span> <span class="err">word(</span><span class="s2">"`numeric_vars'"</span><span class="err">,</span><span class="p">`</span><span class="si">i</span><span class="p">'</span><span class="err">)
</span>		<span class="err">local</span> <span class="err">namej</span> <span class="o">=</span> <span class="err">word(</span><span class="s2">"`numeric_vars'"</span><span class="err">,</span><span class="p">`</span><span class="si">j</span><span class="p">'</span><span class="err">)
</span>		<span class="err">g</span> <span class="err">interact_</span><span class="p">`</span><span class="si">i'_`j' = `namei'*`namej</span><span class="p">'</span><span class="err">
</span>	<span class="err">}
}
</span><span class="c1">
* Standardize everything
</span><span class="err">foreach</span> <span class="err">var</span> <span class="err">of</span> <span class="err">varlist</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span> <span class="err">{
</span>	<span class="err">qui</span> <span class="err">summ</span> <span class="p">`</span><span class="si">var</span><span class="p">'</span><span class="err">
</span>	<span class="err">qui</span> <span class="err">replace</span> <span class="p">`</span><span class="si">var' = (`var</span><span class="p">'</span> <span class="o">-</span> <span class="err">r(mean))/r(sd)
}
</span><span class="c1">
* Use the lasso command to run LASSO
* using sel(cv) to select lambda using cross-validation
* we specify a linear model here, but logit/probit/poisson would work
</span><span class="err">lasso</span> <span class="err">linear</span> <span class="err">wage</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span><span class="err">,</span> <span class="err">sel(cv)
</span><span class="c1">* get list of included coefficients
</span><span class="err">lassocoef
</span><span class="c1">
* We can use elasticnet to run Elastic Net
* By default, alpha will be selected by cross-validation as well
</span><span class="err">elasticnet</span> <span class="err">linear</span> <span class="err">wage</span> <span class="p">`</span><span class="si">numeric_vars</span><span class="p">'</span> <span class="err">f</span><span class="o">*</span><span class="err">_</span><span class="o">*</span> <span class="err">interact_</span><span class="o">*</span><span class="err">,</span> <span class="err">sel(cv)
</span></code></pre></div></div>
          <hr>
          <footer>
              <div class="d-flex mt-2">
                  <p class="text-small text-grey-dk-000 mb-0">
                    <a href="https://github.com/lost-stats/lost-stats.github.io/edit/source/Machine_Learning/penalized_regression.md" id="edit-this-page">Edit this page on GitHub.</a>
                  </p>
              </div>
          </footer>
      </div>
    </div>
      <div class="search-overlay"></div>
  </div>
</body>
</html>
